first, (make sure docker-desktop is running)
    docker-compose -f cli.yml up -d

then,
    docker exec -it ollama ollama run deepseek-r1:8b

  or,
    docker exec -it ollama ollama run deepseek-r1:14b

  or,
    download a GGUF model from https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-32B-GGUF/tree/main
    
    then,
      paste it in data/models folder

    then,
        ( needed only the first time,
            docker exec -it ollama ollama create Deepseek_R1_GGUF_32B_Q2_K -f /root/.ollama/models/Modelfile
        )

    after model is created for docker,
        docker exec -it ollama ollama run Deepseek_R1_GGUF_32B_Q2_K
  
  or,
    docker exec -it ollama ollama run deepseek-coder-v2:16b-lite-instruct-q2_K